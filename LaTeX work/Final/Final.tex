\documentclass[a4paper, 12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{apacite}
\usepackage{enumitem}


\title{Master Thesis - Explainable Machine Learning - Visualization of Random Forests}
\author{Fabio Rougier}
\date{\today}

\begin{document}

\maketitle

\clearpage
\section{Summary}
DO SUMMARY AT THE END

\tableofcontents
\clearpage

\section{Introduction}
WRITE THIS AT THE END
Random Forests (RF) \cite{breiman2001random} are a powerful ensemble method with a low barrier of entry. Because of their
ease of use and performance they are used in many applications. However, they fall short
when it comes to transparency.
On the one hand RFs can offer a multitude of valuable insights into their decision making and the data they
process. On the other hand visualizing this is usually a challenge because of the inherent scale of a RF and the
aggregation of their decision making process. The goal of this work was to provide relative
beginners with a tool to explore a RF on a detailed level.

\subsection{Visualizing Decision Trees}
An obvious approach to visualizing a RF is inspecting the decision trees that constitute
the RF. One example for the visualization of a decision tree is \textit{BaobabView}
\cite{van2011baobabview}. As many other approaches visualizing decision trees, it utilizes
Node-Link Diagrams (NLDs) as its' main visualization. A confusion matrix yields additional
insights into the relations of the underlying features.
However this visualization does fall short when trees grow too large, as it becomes hard to
inspect every individual node and branch of the tree.
This is one of the problems that \textit{TaxonTree} tries to overcome
\cite{parr2003taxontree}. It uses a tree visualization approach that is scalable for large
trees by adding the possibility to zoom, browse and search the tree. While this does
help if a tree grows too large, it does not provide any insight on the general structure of
the tree as a whole.
\linebreak
Generalizing either of the approaches towards RFs is also non trivial. Both simply lack the
scalability in the desired dimension. It also leads into a dangerous territory of focusing too much on
the structure of individual trees. RFs - as all ensemble methods - arrive at their decisions
by combining the decisions of the individual trees. Inspecting and even understanding
individual trees, will only yield limited insights over the RF.

\subsection{Visualizing Random Forests}
To fully understand the structure and decision making of a RF, many aspects of the RF have to
be conveyed by the visualization. First of all typical indicators like a \textit{F1 score}
give an indication of the overall performance. Additionally there are some metrics specific
to RFs that should be included to get a deeper understanding of a particular instance of the
RF, like the \textit{mean impurity} of the individual trees or the \textit{out of bag error}.
With its' unique way of providing a distance measure for features,
a confusion matrix can also yield valuable insights to the relations of the features and how
the RF interprets them. As stated before, the visualization of RFs heavily relies on how it
overcomes the scalability issues of RFs.

\section{Related Work}

\subsection{ReFine}
This approach is rather old, but still worth mentioning, because it highlights the fact,
that visualizing RFs has been a challenge for some time now \cite{kuznetsova2014random}.
In this particular case, the technical implementation is of course out-dated, but
the ideas are still relevant. \textit{ReFine} uses a small multiples view of the trees to give the user
insights from different angles. The main visualization uses icicle plots, as the author
deems them most suitable due to their efficient use of space. While this does allow to
show a considerable number of trees in one view, it does not scale well enough for large
amounts of trees in a RF.
An important distinction raised by the author is that there are different users for RFs,
with very different requirements towards a RF visualization. While a machine learning
expert might be more focused on improving model performance, an analyst or domain expert
would be more concerned about the insights provided by the models.

\subsection{iForest}
The \textit{iForest} visualization is one of the most promising visualization approaches for RFs.
\cite{zhao2018iforest} It focuses on the interpretability of the RF and raises the concern
that many domains would not even consider using RFs because of their lack thereof.
The authors also approach the understanding of RFs by coming from two different angles:
\textit{Feature Analysis} and \textit{Case Based Reasoning}.
Both require different charts and give the user valuable insight into the dataset and
the RF. The elaborate, dashboard-like web application utilizes the benefits
of small multiples and has interconnected and interactive charts, each devoted to offer a
specific perspective. One especially unique part of the dashboard is the use of
\textit{Partial Dependence Plots} to display the RF's classification behavior in regard to
each feature. This is supported by a bar chart of the feature's distribution in order to
support this view with more context.
While the dashboard is a powerful tool, it can be overwhelming for users. It also
requires some in-depth knowledge about RFs in order to come to conclusions or even an
actionable instruction. \textit{iForest} is clearly aimed at supporting data scientists to understand
their own creations and not suited for a domain expert.

\subsection{ExMatrix}
The \textit{ExMatrix} follows an out-of-the-box-thinking approach by breaking up machine
learning models into a set of rules \cite{neto2020explainable} \cite{ming2018rulematrix}.
It is therefore even more flexible because it is not limited
to be used with RFs only, but could be applied to almost any kind of machine learning model.
It is best suited to abstract ensemble models and simplify them. This is however not to be
mistaken with creating surrogates from the given models, as it reflects the underlying
models exactly. By breaking down a RF in said rules, it is possible to display the entire
RF in a matrix structure. It does this by representing columns as features and rows as rules, resulting in
cells as so-called \textit{rules predicates}. This entire rethinking of the RF as a whole allows for
unique graphs and insights in the RFs' decision making. Thinking of the RF as a set of
comparable rules and evaluating those, yields a very deep understanding, both on a
case-based sample level, but also on a global level. While not supported in the original
paper, this would also allow for intricate comparisons of models on the same data set.
The biggest issue with this approach is, that while it does yield powerful insights, it can
be very difficult to convey these insights to a domain expert. While a data scientist can be
expected to wrap their head around the idea of disassembling a RF into a set of rules, this
idea is not intuitive for a domain expert who might already have trouble understanding how
the RF works in the first place.

\subsection{Summary}
While the main challenge of gaining access to the insights and details of the inner workings
of a RF might have been solved already they seem to be hidden behind a kind of complexity
layer. Powerful approaches for RF visualization exist, but there is a need to make them more
accessible for domain experts. Considering not only the audience, but also the intended
use of the visualization is paramount for the visualization to be useful. There is a lot
of value to be derived from the existing work and some of the ideas have influenced this
work.

\section{Methodology}
\subsection {Important Packages}
\subsubsection{Python}
This work was implemented in \textit{Python 3.10.4} \cite{10.5555/1593511}, as it has
become one of the standard programming languages for data science and machine learning.
This allowed the usage of many commonly used libraries, like \textit{NumPy} \cite{harris2020array},
\textit{pandas} \cite{mckinney-proc-scipy-2010}, \textit{scikit-Learn} \cite{scikit-learn} and more.
Using Python also opens up the possibility to further extend this work in the future, while
the libraries and possibilities of Python keep improving and expanding.
Some of the libraries used in this work make use of \textit{Cython} \cite{behnel2011cython} to
speed up the execution of certain functions. This was particularly relevant for this work, as will
be elaborated in a later section. \par
The built-in \textit{pickle} module contains functionalities to serialize and deserialize
\textit{Python} objects.
Since some of the computations made by the backend of this work are quite intensive, the repository
contains \textit{pickle} files of the pre-computed results of a matrix computation. This allows
for a quick display of the two example use cases. \par
Another built-in module used was the \textit{multiprocessing} module. It allows for parallel
execution of methods on multiple CPU cores. As the necessary matrix computations scale with the
number of trees in the forest, it was crucial to speed them up significantly, which was achieved
by using the \textit{Pool} method of the module.

\subsubsection{pandas}
The \textit{pandas} library offers a powerful data structure called \textit{DataFrame}, which in
essence is just a table. Its' implementation is made so convenient and efficient though, that it
allows for both intuitive and performant data manipulation. \par
In this work, \textit{pandas 1.5.0} is used as a backbone throughout the entire lifecycle of the
visualization.

\subsubsection{scikit-Learn}
With the \textit{scikit-Learn 1.1.2} library, machine learning is made easily accessible, even to
beginners, while still providing some more advanced configurations if necessary. \par
For this work, both the \textit{RandomForestClassifier} and the \textit{DecisionTreeClassifier}
are a main part of the processes in the background. The two example use cases, discussed in this
work are based on the data provided by the \textit{scikit-Learn} library, specifically the
\textit{Iris} and the \textit{Digits} dataset. Additionally, the \textit{DBSCAN}
\cite{ester1996density} and \textit{t-SNE} \cite{JMLR:v9:vandermaaten08a} algorithms are used as
provided by the package.

\subsubsection{Streamlit}
\textit{Streamlit 1.13.0} provides users with an incredibly easy entry point to transferring Python
visualizations into the web browser. With a simple \textit{"st.write()"} command, any text,
visual or even {DataFrame} can be displayed in the browser. While the package certainly has its'
limits, it is a great tool for a fast development of dashboards and visualizations. \par
\textit{Streamlit} was used in this work to handle the web application and the user interface
that enables interactions with the visualizations and algorithms. The \textit{Form} class was
particularly useful for creating the sidebar that the user can interact with. Many sliders, paired
with explanations and optional help-texts offer the user a lot of control and clarity when using
the dashboard.
While \textit{Streamlit} has
recently rolled out support for multi-page-apps, this work uses a well known workaround to
achieve the same result, because it allows for more flexibility and did not require a fixed folder
structure of the app.
Some limitations of the package were overcome with the use of \textit{HTML} and \textit{CSS} in
the \textit{Streamlit} code, which is not ideal, but common practice in the \textit{Streamlit}
community.

\subsubsection{Vega-Altair}
Speaking of visualizations, \textit{Vega-Altair 4.2.0} \cite{VanderPlas2018} is a great library for
creating interactive charts, with a great deal of flexibility for customization. It is built
on top of \textit{Vega-Lite} \cite{Satyanarayan2017}, which is a declarative grammar using
the JSON standard for building graphs, that are then rendered using the \textit{Vega-Lite}
compiler. \textit{Vega-Altair}, or \textit{Altair} for short, is especially unique in its'
way of constructing graph, by using \textit{encodings} for each visual element. This syntax
is very intuitive to use makes the library both powerful and easy to use. \par
Every chart in this work is created using \textit{Altair}, which in turn allows the use of
\textit{Altair's} interactive capabilities like brushing and linking. Some of the charts in the
dashboard offer the user the ability to highlight sections and see the corresponding data changes
in a different chart right next to it.

\subsubsection{NetworkX}
\textit{NetworkX 2.8.7} \cite{SciPyProceedings_11} is one of the most popular libraries for
manipulating graphs in Python. It contains many useful functions for traversing, building
and analyzing graphs. \par
Decision Trees are essentially binary trees, which can be represented as graphs. As such,
\textit{NetworkX} was used for some particular graph operations like the graph edit distance.
In order to transform the \textit{DecisionTreeClassifier} into a graph, \textit{PyGraphviz}
was used as an intermediate step.

\subsection{Algorithms}

\subsubsection{Decision Trees and Random Forests}
A RF, as described earlier, is an ensemble method combining multiple decision trees into a
single classifier. By combining multiple decorrelated trees, the tree's performance can be
much better than a single tree, while avoiding overfitting.
\par
Decision trees are one of the most intuitive machine learning approaches, because they
provide an interpretable path for their decisions. They are built recursively by splitting
the training data into subsets based on a threshold value, computed by a predefined measure
like \textit{impurity} or \textit{entropy}. This process is deterministic and can lead to
very high performing models. Unfortunately, they are prone to overfitting the training data,
which makes them less useful in the real world. Pruning and the use of larger training
sets can usually negate this only to a degree. \par

The idea of RFs is to make use of this overfitting problem and turn it into an advantage.
Through a process called \textit{bagging}, each tree is trained on a different subset of the
training data. Additionally, by choosing the splitting feature at each recursive step
randomly, the trees are decorrelated and result in heterogenous set of trees. The most
common way of combining the trees is a majority vote, in the case of classification, or a
mean of the predictions, in the case of regression. \par

Their good performance is not their only strength though. Through libraries like
\textit{scikit-Learn}, RFs can be set up with just a few lines of code. Depending on the size
of the training data, even the training process can be done in a matter of seconds. As
displayed in the dashboard developed in this work, this can deliver extremely high performing
models with very little background knowledge or further tuning from the user. This makes them
a very attractive tool for domain experts. \par

The main downside is the lack of interpretability of RFs. While it would be possible to inspect
individual trees and every single decision they make, it is hard to interpret their impact on
the decisions of the global model.

\subsubsection{Graph Edit Distance}
A crucial algorithm used in the backend of the dashboard is the \textit{graph edit distance}
\cite{sanfeliu1983distance}. It is a basic measure of similarity between two graphs, working in
a similar way as the \textit{Levenshtein Distance} \cite{levenshtein1966binary}, but for graph
structures. It considers two graphs and computes the operations needed to transform one into the
other. Each operation can have a cost attributed to it, which is then summed up to get the final
distance. \par

In this dashboard the metric serves as the central measure of similarity between two trees. The
\textit{NetworkX} implementation of the algorithm allows to specify cost functions for each
operation individually, but uses the same cost for all operations if nothing else is specified.
The default configuration of the \textit{graph edit distance} method does not take into account
the node labels, which is why a custom cost function was used, to ensure that not only the
morphology of the trees is considered, but also the labels. It was also vital to pass the root
nodes of the two trees to the method in order to improve calculation performance. \par

Calculating the \textit{graph edit distance} between two trees is a very expensive operation,
which is why the method was configured to utilize the \textit{timeout} parameter with 0.5 seconds.
The method will then return the best result it could find within the given time. This was tested
and deemed to resemble the best compromise between performance and accuracy. \par

While other metrics exist to compute the similarity between two trees, the \textit{graph edit
    distance} was chosen, because it is intuitive to understand and easy to implement. Since the
basic graph structure in this use case will always be a binary tree, more elaborate metrics
are not necessary.

\subsubsection{Pairwise Distance Matrix Calculation}
The assembly of the pairwise distance matrix was a crucial part of the backend code to get its'
performance up to par. Since the matrix is symmetric, it is only necessary to calculate half of
it. The metric used in calculating each pairwise distance is the aforementioned \textit{graph
    edit distance}, each individual calculation is expensive on its' own. It was therefore critical
to have a fast implementation of the matrix computation overall and to avoid unnecessary
calculations as much as possible. \par

As described in the \textit{Python} subsection, the \textit{multiprocessing Pool} class was
essential in speeding up the computation. It is written in such a way, that the calculating method
expects only a single tree which is compared against all other trees, minus the ones that
have already been compared. This is done through the \textit{map} method, which receives a list
of all the trees and the method to be applied to each of them. This resulted in a significant
speedup and allowed to set the \textit{timeout} parameter of the \textit{graph edit distance}
to a higher value and in turn have more accurate results. The iterative calculation could only
handle timeouts in the milisecond range, which still resulted in calculation times of over 10
minutes, while the current implementation, running on an \textit{AMD Ryzen 5 5600X} 6-Core
Processor with 12 threads, takes about 5 minutes. \par

Obviously, this is still not a fast enough implementation for a user to be run on the fly, which
is why the pairwise distance matrix is only calculated once and then stored in a \textit{pickle}
file. For the two example use cases these initial calculations have already been computed for the
RFs with 100 trees and the \textit{pickle} files are included in the repository, so that the user
will not have to wait for the calculations on startup. \par
% IF ANYTHING MORE GETS PRELOADED, TALK ABOUT IT HERE
After the calculation, the results are normalized, using a \textit{MinMaxScaler}, also from the
\textit{scikit-Learn} library. This is necessary, because the \textit{graph edit distance} can
result in larger values for larger trees, as each operation has a cost associated with it. To
retain the distribution of the distance values as best as possible, the \textit{MinMaxScaler}
was considered appropriate, considering that the resulting distance values have to be positive
and the distribution is not necessarily gaussian.

\subsubsection{DBSCAN}
The main algorithm used in this work to cluster the trees is the \textit{Density-based spatial
    clustering of applications with noise} or \textit{DBSCAN} algorithm. It is
a density-based cluster algorithm, which is capable of finding clusters in high dimensional data.
A clear advantage of the DBSCAN algorithm is that the amount of clusters is not defined as a
hyperparameter, but is determined by the algorithm itself. It is also capable of defining data
points as noise, which makes sense for the given use case, as it is quite possible that a
considerable amount of trees is not associated to any cluster at all. The idea to use the
\textit{DBSCAN} in this context was considered intuitive, as trees can share similar features
starting from their root node and will differ more and more as they grow deeper. Since the
algorithm assumes \textit{core points}, trees with these shared features would be expected to
be in a cluster together and form core-points, while trees with different labels on their first
few levels would be assigned to a different cluster. \par

As described in the previous section, the distance calculation between two trees is computationally
expensive and recalculations should be avoided. The \textit{DBSCAN} algorithm is therefore
implemented by making use of the \textit{precomputed} parameter of the \textit{sklearn}
implementation. The \textit{pairwise distance matrix} is passed to the algorithm as computed
earlier. Which results in a significant speedup, as the distance calculation is the most time
consuming part of the algorithm. The two example use cases have both been configured with default
parameters in order to show a certain behaviour. The results of which will be discussed in the
\textit{Analysis} section. \par

\subsubsection{t-SNE}
The \textit{t-distributed stochastic neighbor embedding} or \textit{t-SNE} algorithm is based on
the \textit{stochastic neighbor embedding} or \textit{SNE} \cite{hinton2002stochastic} algorithm
and is used to visualize high dimensional data in lower dimensional space. By going through two
phases, the algorithm first computes pairwise probability distributions between points, usually
using the euclidian distance. In this case, the \textit{pairwise distance matrix} provides the
results for the \textit{graph edit distance} for this phase. In the second phase, the
\textit{Kullback-Leibler divergence} \cite{csiszar1975divergence} is minimized between every pair
of probability distributions in the low dimensional space. The number of components in the low
dimensional space can also be specified and was set to two for this work.
\textit{t-SNE} is a non-deterministic algorithm, which means that the results will vary slightly
each time it is run. We avoid this in the dashboard by using the \textit{random state} parameter,
which is set to a fixed value. \par
For our use case, the \textit{t-SNE} algorithm is used with the \textit{precomputed} parameter,
just as the \textit{DBSCAN} algorithm before to avoid unnecessary calculations.
The \textit{t-SNE} results are a double edged sword however, because the algorithm will always
output some kind of embedding. This can make it hard to evaluate the output, as the problem is
high dimensional and there is no way to know the \textit{true} cluster assignment.
By presenting the user with both, the \textit{t-SNE} and the \textit{DBSCAN} results, it puts the
resulting cluster assignments into context.

\subsection{Target Audience}
The goal of this work was to provide a tool that is easy to use and has a low barrier of entry.
As the target audience, domain experts with little experience with data science were considered.
Since a RF is not something used by anyone in their daily life, it was expected, that the user
would have at least a basic understanding of statistics and machine learning, but has not yet
been in contact with the concept of a RF. \par
Given this premise, the dashboard has an educational aspiration and is in its' current state
not intended to be used as a tool for data scientists. As such, all graphs are accompanied by
explanations and the user is introduced to concepts one step at a time. Some of the graphs and
and explanations simplify concepts or just briefly touch certain aspects. This is intentional
and has the purpose of not overwhelming the user with too much information at once. The contents
discussed in the dashboard are already quite complex, so every introduction of new concepts
or more elaborate explanations were carefully weighed between the benefit of the explanation
and the risk of overloaded information. \par

\subsection{The Dashboard}
\subsubsection{Backend}
The backend of the dashboard is constructed in a three-layer architecture, separating data,
logic and visualization. While the logic and data layers are more tightly coupled, there is
a clear separation between the creation of the visualizations and the creation of the
dashboard pages. By separating the layers in this way, further development of the dashboard is
made easier, as a change in one layer will not affect the other layers. As stated in the
previous section, the two datasets \textit{Iris} and \textit{Digits} from the
\textit{sci-kit Learn} library are used for the example use cases. It was therefore not
necessary to implement any elaborate data loading process. \par
The data layer as it exists now, mostly loads the respective dataset into a
\textit{pandas Dataframe} and performs some basic preprocessing. \par
The RF training and all other computations are happening in the logic layer. It
contains the code for training the Random Forest, computing feature importances and the calculation
of a distance matrix required for the \textit{DBSCAN} clustering and a\textit{ t-SNE} embedding
of the trees. If the standard use case is selected, the distance matrix is pre-loaded from the
\textit{pickle} file. The results are then assembled in the central \textit{tree Dataframe}, containing
detailed information about each tree in the forest. This assembly is handled by a dedicated class.
After constructing the \textit{tree Dataframe}, two classes construct the \textit{Streamlit} page.
While one of them contains logic and information about the layout of the respective page, the other
creates the individual visualizations. The text segments are loaded from the \textit{markdown} files
located under the \textit{"text"} folder of the app. By separating the creation of individual graphs
from the actual creation of the page in any layout, further development of the dashboard is made
easier.

\subsubsection{Frontend}
The frontend of the dashboard is based on two main components of the code base: The layout, defined
in the respective class and a \textit{*.toml} file, where the theme of the dashboard is determined.
On the left side is a sidebar, containing navigation options for the user. Radio buttons allow to
switch between the different pages, while a dropdown menu offers the option to select between the
two different use cases. The initial use case presented is the \textit{Iris} dataset.
The first page shown to the user is the \textit{Tutorial} page, containing a short welcome message,
explaining what the dashboard is about. What follows is an explanation of the currently selected use
case, decision trees and random forests, supported by some explanatory pictograms.
The goal of this page was to make sure, that anyone accessing the dashboard could get an immediate
idea of what the dashboard is about and have a basic understanding of the topic. Each use case has
a short description of the dataset and also the explanation of the decision tree is altered slightly
to fit the respective dataset.
\par
The second page is the \textit{Dashboard}, where the user is introduced to the use case application
of the RF. When changing to this page, the \textit{Algorithm Parameters} appears in the sidebar. This
section starts with a short warning about the fact, that the dashboard will be reloaded upon pressing
\textit{"Run"} and that this action can take some time.
After this prompt, some parameters can be selected for the dashboard. Each of the parameters has a
help text next to it, that can be expanded by hovering over the question mark. In the help text,
the user is given some basic idea for what a change of the parameter would do.
The only available parameter for
the RF is the number of trees, which ranges between 20 and 200. These boundaries were chosen, because
a random forest with less than 20 trees is less likely to be used in practice and values over 200
would take the matrix calculation excessively long to complete.
Below this slider inside two \textit{streamlit metric} widgets, the user can see the current
\textit{Silhouette Score} \cite{rousseeuw1987silhouettes} of the clustering and the amount of trees that
are currently assigned to a cluster. The \textit{Silhouette Score} gives an indiciation of how well each
point is assigned to its cluster. The score ranges from -1 to 1, with 1 being the best possible score.
It can be computed for each point, as shown in later plots, but also as an average over all points, or
trees in this case. It is important to note at this point, that the Silhouette Score is not optimally
suited to be used for a DBSCAN clustering, as it also classifies points as \textit{noise}. Factoring
these points into the score would artificially decrease the score depending on the amount of noise
detected. This is solved here by not including the noise points in the calculation of the score.
Since this in turn artificially increases the score, especially for clusterings with a large amount of
noise, the user sees the amount of trees currently assigned to a cluster in a metric widget right next
to the \textit{Silhouette Score} metric widget. This puts the score into perspective and the user is
made aware of the fact that the score should not be taken at face value, which is additionally supported
by the explanatory text boxes sourounding the metric widgets and \textit{Silhouette Score} text elements.
\par
Following these metrics, the
\textit{DBSCAN} parameters \textit{'min samples'} and \textit{'eps'} and below that
the parameters \textit{learning rate}, \textit{perplexity} and \textit{early exaggeration} for the
\textit{t-SNE} embedding can be adjusted.
Each parameter has a help text next to it, to explain its' basic behaviour to the user.
Unfortunately, the size of the sidebar is only adjustable by the user and there is currently no
official way to set the standard size of the sidebar to a fixed value.
After introducing the user to the RF with some basic information, the first graph and its' explanation
are shown below. Starting with a simple bar chart, displaying the feature importances of the RF,
the user is introduced to the concept of feature importances. This is the most common graph in the
context of RFs and gives the user a first impression of the inner workings of the RF. The next graph
covers the F1-score of the RF for each class. A blue line indicates the average \textit{F1-score} of the RF to
put this measure into context. Showing the discrepancies between classes can give users a hint of
certain classes, that might be harder to predict than others. An explanation accompanies the graph
and gives a brief explanation of the \textit{F1 score}.
From an analytical perspective it is interesting to see that the RF performs especially well on the
\textit{Iris} dataset, and achieves an \textit{F1 score} of almost 1 for the \textit{setosa} class.
\par
The following chart is a heatmap showing the \textit{pairwise distance matrix} of all trees.
This was constructed by calculating the graph edit distance between all trees with the goal to show
how similar the trees are to each other. The idea behind this, was to exploratively be able to discover
groups of similar trees in the forest and further inspect them. The darker spots in the heat map are
where trees are especially similar to each other. Since this is sorted by the \textit{DBSCAN} clustering,
the user can already see some of these cluster patterns in the heatmap. What follows is a more
elaborate explanation of this idea. It is crucial for the user to understand this concept, as the
subsequent charts are based on this idea. \par
The text also briefly explains the \textit{DBSCAN} algorithm as well as the concept behind the
\textit{Silhouette Score} so that the user is able to interpret the following charts.
The successive chart combines the bar plot shown before, comparing the \textit{F1-score} over the
different classes, but this time discerning between the different clusters. With this, the user can
see which clusters are better or worse at predicting certain classes. Again, a blue line indicates
the average \textit{F1-score} of the RF for the respective class. Additionally, the bars are color
coded according to the \textit{Silhouette Score} of their respective cluster.
It is important to note here, that the \textit{Silhouette Score} is not originally meant to be used
with clusters that identify outliers. The data points classified as \textit{noise} by the algorithm,
are therefore automatically assigned a value of -1. This visually separates the \textit{noise} bars
from the others, while also giving the user a hint, that the \textit{noise} cluster should not be
viewed as a uniform cluster, like the others.
As noted before, especially the \textit{setosa} class performances are very good, but across the
classes and clusters, it is clear that some trees perform better than others.
\par
The \textit{t-SNE} embedding is the last major chart for the user to explore. It shows a two-dimensional
representation of the trees as a scatter plot. The trees are colored according to their respective
\textit{Silhouette Score}. Next to the plot is the \textit{Silhouette Plot} showing how well each
cluster was identified by the \textit{DBSCAN} algorithm. With this two dimensional embedding the user
can have a second look at the clustering. If both algorithms align
on the clusters, chances are that the parameters were chosen correctly. The \textit{t-SNE} algorithm
is not explained in detail, as this would be too much information at this point.
This is the first plot, where brushing comes into play. The user can select a group of points on the
left to see them highlighted in the plot on the right. This gives the user the opportunity to more
deeply explore the trees. \par
The last chart repeats two of the charts that the user already knows from before, but put into a new
and interactive context. With the \textit{t-SNE} plot on the left, the user can again select a group
of trees, but this time the bar chart on the right will show the feature importances of the selected
trees. From here, the user is free to explore the trees of the forest in the regards to their
feature importances and it is possible to see, that certain classes prefer certain features over
others. This is especially interesting for further analysis and combining it with the knowledge of
the preceding charts, that already showed that some clusters are better or worse at predicting certain
classes. \par
The user is then invited to explore the parameters and the other use case through the sidebar to see
how the different parameters affect the clustering results.

\section{Analysis}
\subsection{Random Forest}
RFs performen sehr gut auf Iris, auf Digit immer noch decent ohne viel tuning
Noch was zu feature importances sagen

\subsection{Class Performance Comparison}

\subsection{Pairwise Distance Matrix}

\subsection{DBSCAN}

\subsection{t-SNE}

\section{Conclusions}

\subsection{Future Work}

\section{Statement of Independent Work}

\clearpage
\bibliographystyle{apacite}
\bibliography{FinalReferences}
\end{document}