\documentclass[a4paper, 12pt]{article}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{apacite}
\usepackage{enumitem}


\title{Master Thesis - Explainable Machine Learning - Visualization of Random Forests}
\author{Fabio Rougier}
\date{\today}

\begin{document}

\maketitle

\clearpage
\section{Summary}
DO SUMMARY AT THE END

\tableofcontents
\clearpage

\section{Introduction}
WRITE THIS AT THE END
Random Forests (RF) \cite{breiman2001random} are a powerful ensemble method with a low barrier of entry. Because of their
ease of use and performance they are used in many applications. However, they fall short
when it comes to transparency.
On the one hand RFs can offer a multitude of valuable insights into their decision making and the data they
process. On the other hand visualizing this is usually a challenge because of the inherent scale of a RF and the
aggregation of their decision making process. The goal of this work was to provide relative
beginners with a tool to explore a RF on a detailed level.

\subsection{Visualizing Decision Trees}
An obvious approach to visualizing a RF is inspecting the decision trees that constitute
the RF. One example for the visualization of a decision tree is \textit{BaobabView}
\cite{van2011baobabview}. As many other approaches visualizing decision trees, it utilizes
Node-Link Diagrams (NLDs) as its' main visualization. A confusion matrix yields additional
insights into the relations of the underlying features.
However this visualization does fall short when trees grow too large, as it becomes hard to
inspect every individual node and branch of the tree.
This is one of the problems that \textit{TaxonTree} tries to overcome
\cite{parr2003taxontree}. It uses a tree visualization approach that is scalable for large
trees by adding the possibility to zoom, browse and search the tree. While this does
help if a tree grows too large, it does not provide any insight on the general structure of
the tree as a whole.
\linebreak
Generalizing either of the approaches towards RFs is also non trivial. Both simply lack the
scalability in the desired dimension. It also leads into a dangerous territory of focusing too much on
the structure of individual trees. RFs - as all ensemble methods - arrive at their decisions
by combining the decisions of the individual trees. Inspecting and even understanding
individual trees, will only yield limited insights over the RF.

\subsection{Visualizing Random Forests}
To fully understand the structure and decision making of a RF, many aspects of the RF have to
be conveyed by the visualization. First of all typical indicators like a \textit{F1 score}
give an indication of the overall performance. Additionally there are some metrics specific
to RFs that should be included to get a deeper understanding of a particular instance of the
RF, like the \textit{mean impurity} of the individual trees or the \textit{out of bag error}.
With its' unique way of providing a distance measure for features,
a confusion matrix can also yield valuable insights to the relations of the features and how
the RF interprets them. As stated before, the visualization of RFs heavily relies on how it
overcomes the scalability issues of RFs.

\section{Related Work}

\subsection{ReFine}
This approach is rather old, but still worth mentioning, because it highlights the fact,
that visualizing RFs has been a challenge for some time now \cite{kuznetsova2014random}.
In this particular case, the technical implementation is of course out-dated, but
the ideas are still relevant. \textit{ReFine} uses a small multiples view of the trees to give the user
insights from different angles. The main visualization uses icicle plots, as the author
deems them most suitable due to their efficient use of space. While this does allow to
show a considerable number of trees in one view, it does not scale well enough for large
amounts of trees in a RF.
An important distinction raised by the author is that there are different users for RFs,
with very different requirements towards a RF visualization. While a machine learning
expert might be more focused on improving model performance, an analyst or domain expert
would be more concerned about the insights provided by the models.

\subsection{iForest}
The \textit{iForest} visualization is one of the most promising visualization approaches for RFs.
\cite{zhao2018iforest} It focuses on the interpretability of the RF and raises the concern
that many domains would not even consider using RFs because of their lack thereof.
The authors also approach the understanding of RFs by coming from two different angles:
\textit{Feature Analysis} and \textit{Case Based Reasoning}.
Both require different charts and give the user valuable insight into the dataset and
the RF. The elaborate, dashboard-like web application utilizes the benefits
of small multiples and has interconnected and interactive charts, each devoted to offer a
specific perspective. One especially unique part of the dashboard is the use of
\textit{Partial Dependence Plots} to display the RF's classification behavior in regard to
each feature. This is supported by a bar chart of the feature's distribution in order to
support this view with more context.
While the dashboard is a powerful tool, it can be overwhelming for users. It also
requires some in-depth knowledge about RFs in order to come to conclusions or even an
actionable instruction. \textit{iForest} is clearly aimed at supporting data scientists to understand
their own creations and not suited for a domain expert.

\subsection{ExMatrix}
The \textit{ExMatrix} follows an out-of-the-box-thinking approach by breaking up machine
learning models into a set of rules \cite{neto2020explainable} \cite{ming2018rulematrix}.
It is therefore even more flexible because it is not limited
to be used with RFs only, but could be applied to almost any kind of machine learning model.
It is best suited to abstract ensemble models and simplify them. This is however not to be
mistaken with creating surrogates from the given models, as it reflects the underlying
models exactly. By breaking down a RF in said rules, it is possible to display the entire
RF in a matrix structure. It does this by representing columns as features and rows as rules, resulting in
cells as so-called \textit{rules predicates}. This entire rethinking of the RF as a whole allows for
unique graphs and insights in the RFs' decision making. Thinking of the RF as a set of
comparable rules and evaluating those, yields a very deep understanding, both on a
case-based sample level, but also on a global level. While not supported in the original
paper, this would also allow for intricate comparisons of models on the same data set.
The biggest issue with this approach is, that while it does yield powerful insights, it can
be very difficult to convey these insights to a domain expert. While a data scientist can be
expected to wrap their head around the idea of disassembling a RF into a set of rules, this
idea is not intuitive for a domain expert who might already have trouble understanding how
the RF works in the first place.

\subsection{Summary}
While the main challenge of gaining access to the insights and details of the inner workings
of a RF might have been solved already they seem to be hidden behind a kind of complexity
layer. Powerful approaches for RF visualization exist, but there is a need to make them more
accessible for domain experts. Considering not only the audience, but also the intended
use of the visualization is paramount for the visualization to be useful. There is a lot
of value to be derived from the existing work and some of the ideas have influenced this
work.

\section{Methodology}
\subsection {Important Packages}
\subsubsection{Python}
This work was implemented in \textit{Python 3.10.4} \cite{10.5555/1593511}, as it has
become one of the standard programming languages for data science and machine learning.
This allowed the usage of many commonly used libraries, like \textit{NumPy} \cite{harris2020array},
\textit{pandas} \cite{mckinney-proc-scipy-2010}, \textit{scikit-Learn} \cite{scikit-learn} and more.
Using Python also opens up the possibility to further extend this work in the future, while
the libraries and possibilities of Python keep improving and expanding.
Some of the libraries used in this work make use of \textit{Cython} \cite{behnel2011cython} to
speed up the execution of certain functions. This was particularly relevant for this work, as will
be elaborated in a later section. \newline
The built-in \textit{pickle} module contains functionalities to serialize and deserialize
\textit{Python} objects.
Since some of the computations made by the backend of this work are quite intensive, the repository
contains \textit{pickle} files of the pre-computed results of a matrix computation. This allows
for a quick display of the two example use cases. \newline
Another built-in module used was the \textit{multiprocessing} module. It allows for parallel
execution of methods on multiple CPU cores. As the necessary matrix computations scale with the
number of trees in the forest, it was crucial to speed them up significantly, which was achieved
by using the \textit{Pool} method of the module.

\subsubsection{pandas}
The \textit{pandas} library offers a powerful data structure called \textit{DataFrame}, which in
essence is just a table. Its' implementation is made so convenient and efficient though, that it
allows for both intuitive and performant data manipulation. \newline
In this work, \textit{pandas 1.5.0} is used as a backbone throughout the entire lifecycle of the
visualization.

\subsubsection{scikit-Learn}
With the \textit{scikit-Learn 1.1.2} library, machine learning is made easily accessible, even to
beginners, while still providing some more advanced configurations if necessary. \newline
For this work, both the \textit{RandomForestClassifier} and the \textit{DecisionTreeClassifier}
are a main part of the processes in the background. The two example use cases, discussed in this
work are based on the data provided by the \textit{scikit-Learn} library, specifically the
\textit{Iris} and the \textit{Digits} dataset. Additionally, the \textit{DBSCAN} and
\textit{t-SNE} algorithms are used as provided by the package.

\subsubsection{Streamlit}
\textit{Streamlit 1.13.0} provides users with an incredibly easy entry point to transferring Python
visualizations into the web browser. With a simple \textit{"st.write()"} command, any text,
visual or even {DataFrame} can be displayed in the browser. While the package certainly has its'
limits, it is a great tool for a fast development of dashboards and visualizations. \newline
\textit{Streamlit} was used in this work to handle the web application and the user interface
that enables interactions with the visualizations and algorithms. The \textit{Form} class was
particularly useful for creating the sidebar that the user can interact with. Many sliders, paired
with explanations and optional help-texts offer the user a lot of control and clarity when using
the dashboard.
While \textit{Streamlit} has
recently rolled out support for multi-page-apps, this work uses a well known workaround to
achieve the same result, because it allows for more flexibility and did not require a fixed folder
structure of the app.
Some limitations of the package were overcome with the use of \textit{HTML} and \textit{CSS} in
the \textit{Streamlit} code, which is not ideal, but common practice in the \textit{Streamlit}
community.

\subsubsection{Vega-Altair}
Speaking of visualizations, \textit{Vega-Altair 4.2.0} \cite{VanderPlas2018} is a great library for
creating interactive charts, with a great deal of flexibility for customization. It is built
on top of \textit{Vega-Lite} \cite{Satyanarayan2017}, which is a declarative grammar using
the JSON standard for building graphs, that are then rendered using the \textit{Vega-Lite}
compiler. \textit{Vega-Altair}, or \textit{Altair} for short, is especially unique in its'
way of constructing graph, by using \textit{encodings} for each visual element. This syntax
is very intuitive to use makes the library both powerful and easy to use. \newline
Every chart in this work is created using \textit{Altair}, which in turn allows the use of
\textit{Altair's} interactive capabilities like brushing and linking. Some of the charts in the
dashboard offer the user the ability to highlight sections and see the corresponding data changes
in a different chart right next to it.

\subsubsection{NetworkX}
\textit{NetworkX 2.8.7} \cite{SciPyProceedings_11} is one of the most popular libraries for
manipulating graphs in Python. It contains many useful functions for traversing, building
and analyzing graphs. \newline
Decision Trees are essentially binary trees, which can be represented as graphs. As such,
\textit{NetworkX} was used for some particular graph operations like the graph edit distance.
In order to transform the \textit{DecisionTreeClassifier} into a graph, \textit{PyGraphviz}
was used as an intermediate step.

\subsection{Decision Trees and Random Forests}
A RF, as described earlier, is an ensemble method combining multiple decision trees into a
single classifier. By combining multiple decorrelated trees, the tree's performance can be
much better than a single tree, while avoiding overfitting.
\newline
Decision trees are one of the most intuitive machine learning approaches, because they
provide an interpretable path for their decisions. They are built recursively by splitting
the training data into subsets based on a threshold value, computed by a predefined measure
like \textit{impurity} or \textit{entropy}. This process is deterministic and can lead to
very high performing models. Unfortunately, they are prone to overfitting the training data,
which makes them less useful in the real world. Pruning and the use of larger training
sets can usually negate this only to a degree. \newline

The idea of RFs is to make use of this overfitting problem and turn it into an advantage.
Through a process called \textit{bagging}, each tree is trained on a different subset of the
training data. Additionally, by choosing the splitting feature at each recursive step
randomly, the trees are decorrelated and result in heterogenous set of trees. The most
common way of combining the trees is a majority vote, in the case of classification, or a
mean of the predictions, in the case of regression. \newline

Their good performance is not their only strength though. Through libraries like
\textit{scikit-Learn}, RFs can be set up with just a few lines of code. Depending on the size
of the training data, even the training process can be done in a matter of seconds. As
displayed in the dashboard developed in this work, this can deliver extremely high performing
models with very little background knowledge or further tuning from the user. This makes them
a very attractive tool for domain experts. \newline
The main downside is the lack of interpretability of RFs. While it would be possible to inspect
individual trees and every single decision they make, it is hard to interpret their impact on
the decisions of the global model.

\subsection{The Dashboard}
\subsubsection{Backend}
The backend of the dashboard is constructed in a three-layer architecture, separating data,
logic and visualization. While the logic and data layers are more tightly coupled, there is
a clear separation between the creation of the visualizations and the creation of the
dashboard pages. By separating the layers in this way, further development of the dashboard is
made easier, as a change in one layer will not affect the other layers. As stated in the
previous section, the two datasets \textit{Iris} and \textit{Digits} from the
\textit{sci-kit Learn} library are used for the example use cases. It was therefore not
necessary to implement any elaborate data loading process. \newline
The data layer as it exists now, mostly loads the respective dataset into a
\textit{pandas Dataframe} and performs some basic preprocessing. \newline
The RF training and all other computations are happening in the logic layer. It
contains the code for training the Random Forest, computing feature importances and the calculation
of a distance matrix required for the \textit{DBSCAN} clustering and a\textit{ t-SNE} embedding
of the trees. If the standard use case is selected, the distance matrix is pre-loaded from the
\textit{pickle} file. The results are then assembled in the central \textit{tree Dataframe}, containing
detailed information about each tree in the forest. This assembly is handled by a dedicated class.
After constructing the \textit{tree Dataframe}, two classes construct the \textit{Streamlit} page.
While one of them contains logic and information about the layout of the respective page, the other
creates the individual visualizations. The text segments are loaded from the \textit{markdown} files
located under the \textit{"text"} folder of the app. By separating the creation of individual graphs
from the actual creation of the page in any layout, further development of the dashboard is made
easier.

\subsubsection{Frontend}
The frontend of the dashboard is based on two main components of the code base: The layout, defined
in the respective class and a \textit{*.toml} file, where the theme of the dashboard is determined.
On the left side is a sidebar, containing navigation options for the user. Radio buttons allow to
switch between the different pages, while a dropdown menu offers the option to select between the
two different use cases. The initial use case presented is the \textit{Iris} dataset.
\newline
The first page shown to the user is the \textit{Tutorial} page, containing a short welcome message,
explaining what the dashboard is about. What follows is an explanation of the currently selected use
case, decision trees and random forests, supported by some explanatory pictograms.
The goal of this page was to make sure, that anyone accessing the dashboard could get an immediate
idea of what the dashboard is about and have a basic understanding of the topic. Each use case has
a short description of the dataset and also the explanation of the decision tree is altered slightly
to fit the respective dataset.
\newline
The second page is the \textit{Dashboard}, where the user is introduced to the use case application
of the RF. When changing to this page, the \textit{Algorithm Parameters} appears in the sidebar. This
section starts with a short warning about the fact, that the dashboard will be reloaded upon pressing
\textit{"Run"} and that this action can take some time.
After this prompt, some parameters can be selected for the dashboard. Each of the parameters has a
help text next to it, that can be expanded by hovering over the question mark. In the help text,
the user is given some basic idea for what a change of the parameter would do.
The only available parameter for
the RF is the number of trees, which ranges between 20 and 200. These boundaries were chosen, because
a random forest with less than 20 trees is less likely to be used in practice and values over 200
would take the matrix calculation excessively long to complete. Following the number of trees, the
\textit{DBSCAN} parameters \textit{'min samples'} and \textit{'eps'} and below that
the parameters \textit{learning rate}, \textit{perplexity} and \textit{early exaggeration} for the
\textit{t-SNE} embedding can be adjusted.
Unfortunately, the size of the sidebar is only adjustable by the user and there is currently no
official way to set the standard size of the sidebar to a fixed value.
After introducing the user to the RF with some basic information, the first graph and its' explanation
are shown below. Starting with a simple bar chart, displaying the feature importances of the RF,
the user is introduced to the concept of feature importances. This is the most common graph in the
context of RFs and gives the user a first impression of the inner workings of the RF. The next graph
covers the F1-score of the RF for each class. A blue line indicates the average \textit{F1-score} of the RF to
put this measure into context. Showing the discrepancies between classes can give users a hint of
certain classes, that might be harder to predict than others. An explanation accompanies the graph
and gives a brief explanation of the \textit{F1 score}. \newline
The following chart is \textit{pairwise distance matrix} of all trees. This was constructed by
calculating the graph edit distance between all trees with the goal to show



\clearpage
\bibliographystyle{apacite}
\bibliography{FinalReferences}
\end{document}